#!/usr/bin/env python3
"""
å¿«é€Ÿå¯åŠ¨è„šæœ¬

å¿«é€Ÿå¯åŠ¨å¹¶è¿è¡Œä¸€ä¸ªç®€å•çš„å·¥ä½œæµç¤ºä¾‹
æ— éœ€é…ç½®ï¼Œå¼€ç®±å³ç”¨
"""
import asyncio
import os
import sys
import tempfile
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from core.context import ctx
from ext.workflow import WorkflowManager
from ext.workflow.tasks import schedule_workflow_start, schedule_workflow_resume
from ext.ext_tortoise.models.knowledge_base import Workflow
from ext.ext_tortoise.enums import WorkflowStatusEnum
from loguru import logger


def setup_logger():
    """é…ç½®ç®€å•çš„æ—¥å¿—"""
    logger.remove()
    logger.add(
        sys.stdout,
        format="<green>{time:HH:mm:ss}</green> | <level>{level: <7}</level> | <level>{message}</level>",
        level="INFO",
    )


def create_temp_file(content: str) -> str:
    """åˆ›å»ºä¸´æ—¶æ–‡ä»¶"""
    fd, path = tempfile.mkstemp(suffix=".txt", text=True)
    with os.fdopen(fd, 'w', encoding='utf-8') as f:
        f.write(content)
    return path


async def quick_start():
    """å¿«é€Ÿå¯åŠ¨å·¥ä½œæµ"""
    setup_logger()

    logger.info("=" * 60)
    logger.info("Workflow Quick Start")
    logger.info("=" * 60)

    # 1. åˆ›å»ºä¸´æ—¶æ–‡ä»¶
    sample_text = """Hello, Workflow System!
This is a quick demonstration of the workflow engine.
The system will process this file through multiple tasks:
1. Fetch file
2. Load and analyze it
3. Generate a summary
"""
    file_path = create_temp_file(sample_text)
    logger.success(f"âœ“ Created sample file: {file_path}")

    # 2. é…ç½®ç®€å•çš„ä¸²è¡Œå·¥ä½œæµ
    workflow_config = {
        "fetch_file": {
            "input": {"file_path": file_path},
            "execute_params": {"task_name": "workflow_activity.FetchFileTask"},
            "depends_on": []
        },
        "load_file": {
            "execute_params": {"task_name": "workflow_activity.LoadFileTask"},
            "depends_on": ["fetch_file"]
        },
        "replace_content": {
            "execute_params": {"task_name": "workflow_activity.ReplaceContentTask"},
            "depends_on": ["load_file"],
            "input": {"replace_rules": []}
        },
        "summary": {
            "execute_params": {"task_name": "workflow_activity.SummaryTask"},
            "depends_on": ["replace_content"],
            "input": {"max_length": 100}
        }
    }

    logger.success("âœ“ Workflow configured (4 tasks)")
    logger.info("  Task flow: fetch_file â†’ load_file â†’ replace_content â†’ summary")

    # 3. å¯åŠ¨å·¥ä½œæµ
    logger.info("\n" + "=" * 60)
    logger.info("Starting Workflow")
    logger.info("=" * 60)

    logger.info("\nğŸš€ Starting workflow...")
    logger.info("Note: Celery Worker must be running in another terminal")
    logger.info("If workflow stalls, check if worker is running:")
    logger.info("  uv run celery -A ext.ext_celery.worker worker -l info\n")
    try:

        import uuid
        workflow_uid = uuid.uuid4()

        # åˆ›å»ºå·¥ä½œæµè®°å½•
        workflow = await Workflow.create(
            uid=workflow_uid,
            config=workflow_config,
            config_format="dict",
            status=WorkflowStatusEnum.pending.value,
        )

        await schedule_workflow_start(
            workflow_uid=workflow_uid,
            config=workflow_config,
            config_format="dict",
            initial_inputs={},
            use_async=False
        )

        logger.success(f"âœ“ Workflow started: {workflow_uid}")

        # workflow_uid = await schedule_workflow_resume(workflow_uid, use_async=False)
    except Exception as e:
        logger.error(f"\nâœ— Failed to start workflow: {e}")
        logger.error("\n" + "=" * 60)
        logger.error("Troubleshooting")
        logger.error("=" * 60)
        logger.error("\n1. Check if Celery Worker is running:")
        logger.error("   Open another terminal and run:")
        logger.error("   uv run celery -A ext.ext_celery.worker worker -l info")
        logger.error("\n2. Check Redis connection:")
        logger.error("   redis-cli ping")
        logger.error("\n3. Check PostgreSQL connection:")
        logger.error("   pg_isready")
        logger.error("\n4. View detailed logs:")
        logger.error("   tail -f workflow_quick_start.log")
        logger.error("\n" + "=" * 60)
        return

    # 4. ç­‰å¾…å®Œæˆ
    logger.info("\nâ³ Waiting for workflow to complete...")
    logger.info("Press Ctrl+C to stop waiting\n")

    max_wait = 60  # æœ€å¤šç­‰å¾… 60 ç§’
    for i in range(max_wait):
        await asyncio.sleep(1)

        workflow = await WorkflowManager.get_workflow_by_uid(workflow_uid)
        if not workflow:
            logger.error("âœ— Workflow not found")
            return

        if workflow.status.value in ["completed", "failed"]:
            break

        # æ¯ 5 ç§’æ˜¾ç¤ºä¸€æ¬¡è¿›åº¦
        if (i + 1) % 5 == 0:
            activities = await WorkflowManager.get_activities_by_workflow(workflow_uid)
            completed = sum(1 for a in activities if a.status.value == "completed")
            total = len(activities)
            logger.info(f"  Progress: {completed}/{total} tasks completed")

    # 5. æ˜¾ç¤ºç»“æœ
    logger.info("\n" + "=" * 60)
    logger.info("Workflow Result")
    logger.info("=" * 60)

    workflow = await WorkflowManager.get_workflow_by_uid(workflow_uid)
    logger.info(f"\nStatus: {workflow.status.value}")

    if workflow.status.value == "completed":
        logger.success("âœ… Workflow completed successfully!")

        # æ˜¾ç¤ºæ¯ä¸ªä»»åŠ¡çš„ç»“æœ
        activities = await WorkflowManager.get_activities_by_workflow(workflow_uid)
        logger.info("\nTask Results:")

        for activity in activities:
            if activity.output:
                logger.info(f"\n  ğŸ“‹ {activity.name}:")
                output = activity.output
                for key, value in output.items():
                    if key == "metadata":
                        continue
                    if isinstance(value, str) and len(value) > 100:
                        logger.info(f"     {key}: {value[:100]}...")
                    else:
                        logger.info(f"     {key}: {value}")
    else:
        logger.error("âœ— Workflow failed!")

        # æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
        activities = await WorkflowManager.get_activities_by_workflow(workflow_uid)
        for activity in activities:
            if activity.status.value == "failed" and activity.error_message:
                logger.error(f"\n  âŒ {activity.name}: {activity.error_message}")

    # 6. æ¸…ç†
    logger.info("\n" + "=" * 60)
    logger.info("Cleanup")
    logger.info("=" * 60)

    try:
        os.unlink(file_path)
        logger.success("âœ“ Removed temporary file")
    except:
        pass

    logger.info("\n" + "=" * 60)
    logger.success("ğŸ‰ Quick Start Complete!")
    logger.info("=" * 60)
    logger.info("\nNext steps:")
    logger.info("  1. Run full demo: python ext/workflow/demo.py")
    logger.info("  2. Read documentation: ext/workflow/README.md")
    logger.info("  3. Create your own custom tasks")
    logger.info("\n")


async def main():
    async with ctx():
        await quick_start()


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        logger.info("\n\nInterrupted by user")
        sys.exit(0)
    except Exception as e:
        logger.exception(f"Quick start failed: {e}")
        sys.exit(1)
